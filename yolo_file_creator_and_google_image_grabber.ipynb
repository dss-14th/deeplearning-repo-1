{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로젝트 소개: 가족상봉 도우미 (백화점 ver.) \n",
    "\n",
    "- 상황 가정\n",
    "    - 백화점에서 부모님 혹은 자식들을 잃어버린 상황 가정\n",
    "    - 사람이 많은 환경에서 구별하기 어려운 상황 가정\n",
    "\n",
    "- 접근\n",
    "    - 자료수집\n",
    "        - 인물 특징을 입력 받는다\n",
    "        - 수집한 인물 특징을 가지고 이미지 자료 수집해서 라벨링\n",
    "        - 라벨링된 데이터 obj (학습 데이터 폴더)와 test (validation 데이터 폴더)로 복사해서 저장\n",
    "    - 학습\n",
    "        - 라벨링된 데이터 로컬에서 구글 콜랩으로 받아오기\n",
    "        - cfg 설정\n",
    "        - obj.names, obj.data\n",
    "        - train & validation 데이터 tf 형식으로 변환\n",
    "        - 변환된 데이터 YOLOv4 DEEPSORT로 학습\n",
    "    - detect/track\n",
    "        - 어느 정도 이상의 threshold 이상으로 유사하게 detect된 인물 실시간 CCTV 영상, 위치와 함께 띄워주기:\n",
    "            - detect된 인물을 detect 대신 tracking으로 넘어갈 수 있나? (tracking은 identification 또한 할 수 있어야한다)\n",
    "            - detect되다말면 깜빡임 현상이 예상이 된다.\n",
    "\n",
    "- !기타:\n",
    "    - 시행착오 과정\n",
    "    - 욜로와 CNN의 가장 큰 특징 차이는 detect하는 속도이다. 욜로와 CNN은 어떻게 다르길래 이런 성능의 차이가 나타나는 것일까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자료수집"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/theAIGuysCode/Download-Google-Images.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images\n"
     ]
    }
   ],
   "source": [
    "%cd Download-Google-Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading imutils-0.5.3.tar.gz (17 kB)\n",
      "Requirement already satisfied: requests in /Users/dy/opt/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (2.22.0)\n",
      "Requirement already satisfied: opencv-python in /Users/dy/opt/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (4.4.0.46)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/dy/opt/anaconda3/lib/python3.7/site-packages (from requests->-r requirements.txt (line 2)) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/dy/opt/anaconda3/lib/python3.7/site-packages (from requests->-r requirements.txt (line 2)) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dy/opt/anaconda3/lib/python3.7/site-packages (from requests->-r requirements.txt (line 2)) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/dy/opt/anaconda3/lib/python3.7/site-packages (from requests->-r requirements.txt (line 2)) (2.8)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/dy/opt/anaconda3/lib/python3.7/site-packages (from opencv-python->-r requirements.txt (line 3)) (1.18.5)\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.3-py3-none-any.whl size=25850 sha256=15e56adce2b27a25de37376269a50c58f9c1cf1568bb8e9db51425a096b621d4\n",
      "  Stored in directory: /Users/dy/Library/Caches/pip/wheels/fc/9c/6d/1826267c72afa51b564c9c6e0f66abc806879338bc593a2270\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!mkdir images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 싱글 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 클래스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the race of the person? e.g. asian asian\n",
      "describe the person. e.g. woman, man, boy, girl, senior? woman\n",
      "describe the most outstanding color of the persons outfit. e.g. pink pink\n",
      "what ws the outfit? e.g. tshirt tshirt\n"
     ]
    }
   ],
   "source": [
    "# 클래스문 자동 작성 완성\n",
    "\n",
    "race = input('what is the race of the person? e.g. asian ')# 주로 백인 위주로 이미지가 검색된다 \n",
    "gender_and_age = input('describe the person. e.g. woman, man, boy, girl, senior? ') # e.g. man, boy, girl, grandma, senior\n",
    "color_of_outfit = input('describe the most outstanding color of the persons outfit. e.g. pink ')\n",
    "type_of_outfit = input('what ws the outfit? e.g. tshirt ') # e.g. top, shirt, jacket, jeans\n",
    "\n",
    "if race not in ['white', 'caucasian']:\n",
    "    class_ = '{} {} in {} {}'.format(race, gender_and_age, color_of_outfit, type_of_outfit)\n",
    "else:\n",
    "    class_ = '{} in {} {}'.format(gender_and_age, color_of_outfit, type_of_outfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images\n"
     ]
    }
   ],
   "source": [
    "%cd images\n",
    "\n",
    "class__ = re.sub(' ', '_', class_.strip())\n",
    "if class__ not in os.listdir():\n",
    "    !mkdir {class__}\n",
    "else:\n",
    "    print('{class__} directory already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'urls.txt' in os.listdir(str(os.path.join(Path.home(), \"Downloads\"))):\n",
    "    print('before proceeding, a urls.txt file already exists in your downloads directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-255-61a7b1a41017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 여기서부터는 수작업\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 여기서부터는 수작업\n",
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 생성된 클래스 이미지 자료 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asian woman in pink tshirt\n"
     ]
    }
   ],
   "source": [
    "print(class_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글 이미지에서:\n",
    "# </원하는 클래스> 입력 후\n",
    "# 원하는 이미지 갯수만큼 뜨게 페이지 아래로 스크롤 (디폴트값으로 구글 이미지에서 스크롤링 안했을때 뜨는 이미지 개수는 100개다)\n",
    "# 개발자 모드 콘솔 탭에서 console.js 한줄 한줄씩 입력 후 urls.txt 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "#  * simulate a right-click event so we can grab the image URL using the\n",
    "#  * context menu alleviating the need to navigate to another page\n",
    "#  *\n",
    "#  * attributed to @jmiserez: http://pyimg.co/9qe7y\n",
    "#  *\n",
    "#  * @param   {object}  element  DOM Element\n",
    "#  *\n",
    "#  * @return  {void}\n",
    "#  */\n",
    "# function simulateRightClick( element ) {\n",
    "#     var event1 = new MouseEvent( 'mousedown', {\n",
    "#         bubbles: true,\n",
    "#         cancelable: false,\n",
    "#         view: window,\n",
    "#         button: 2,\n",
    "#         buttons: 2,\n",
    "#         clientX: element.getBoundingClientRect().x,\n",
    "#         clientY: element.getBoundingClientRect().y\n",
    "#     } );\n",
    "#     element.dispatchEvent( event1 );\n",
    "#     var event2 = new MouseEvent( 'mouseup', {\n",
    "#         bubbles: true,\n",
    "#         cancelable: false,\n",
    "#         view: window,\n",
    "#         button: 2,\n",
    "#         buttons: 0,\n",
    "#         clientX: element.getBoundingClientRect().x,\n",
    "#         clientY: element.getBoundingClientRect().y\n",
    "#     } );\n",
    "#     element.dispatchEvent( event2 );\n",
    "#     var event3 = new MouseEvent( 'contextmenu', {\n",
    "#         bubbles: true,\n",
    "#         cancelable: false,\n",
    "#         view: window,\n",
    "#         button: 2,\n",
    "#         buttons: 0,\n",
    "#         clientX: element.getBoundingClientRect().x,\n",
    "#         clientY: element.getBoundingClientRect().y\n",
    "#     } );\n",
    "#     element.dispatchEvent( event3 );\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "#  * grabs a URL Parameter from a query string because Google Images\n",
    "#  * stores the full image URL in a query parameter\n",
    "#  *\n",
    "#  * @param   {string}  queryString  The Query String\n",
    "#  * @param   {string}  key          The key to grab a value for\n",
    "#  *\n",
    "#  * @return  {string}               value\n",
    "#  */\n",
    "# function getURLParam( queryString, key ) {\n",
    "#     var vars = queryString.replace( /^\\?/, '' ).split( '&' );\n",
    "#     for ( let i = 0; i < vars.length; i++ ) {\n",
    "#         let pair = vars[ i ].split( '=' );\n",
    "#         if ( pair[0] == key ) {\n",
    "#             return pair[1];\n",
    "#         }\n",
    "#     }\n",
    "#     return false;\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "#  * Generate and automatically download a txt file from the URL contents\n",
    "#  *\n",
    "#  * @param   {string}  contents  The contents to download\n",
    "#  *\n",
    "#  * @return  {void}\n",
    "#  */\n",
    "# function createDownload( contents ) {\n",
    "#     var hiddenElement = document.createElement( 'a' );\n",
    "#     hiddenElement.href = 'data:attachment/text,' + encodeURI( contents );\n",
    "#     hiddenElement.target = '_blank';\n",
    "#     hiddenElement.download = 'urls.txt';\n",
    "#     hiddenElement.click();\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "#  * grab all URLs va a Promise that resolves once all URLs have been\n",
    "#  * acquired\n",
    "#  *\n",
    "#  * @return  {object}  Promise object\n",
    "#  */\n",
    "# function grabUrls() {\n",
    "#     var urls = [];\n",
    "#     return new Promise( function( resolve, reject ) {\n",
    "#         var count = document.querySelectorAll(\n",
    "#         \t'.isv-r a:first-of-type' ).length,\n",
    "#             index = 0;\n",
    "#         Array.prototype.forEach.call( document.querySelectorAll(\n",
    "#         \t'.isv-r a:first-of-type' ), function( element ) {\n",
    "#             // using the right click menu Google will generate the\n",
    "#             // full-size URL; won't work in Internet Explorer\n",
    "#             // (http://pyimg.co/byukr)\n",
    "#             simulateRightClick( element.querySelector( ':scope img' ) );\n",
    "#             // Wait for it to appear on the <a> element\n",
    "#             var interval = setInterval( function() {\n",
    "#                 if ( element.href.trim() !== '' ) {\n",
    "#                     clearInterval( interval );\n",
    "#                     // extract the full-size version of the image\n",
    "#                     let googleUrl = element.href.replace( /.*(\\?)/, '$1' ),\n",
    "#                         fullImageUrl = decodeURIComponent(\n",
    "#                         \tgetURLParam( googleUrl, 'imgurl' ) );\n",
    "#                     if ( fullImageUrl !== 'false' ) {\n",
    "#                         urls.push( fullImageUrl );\n",
    "#                     }\n",
    "#                     // sometimes the URL returns a \"false\" string and\n",
    "#                     // we still want to count those so our Promise\n",
    "#                     // resolves\n",
    "#                     index++;\n",
    "#                     if ( index == ( count - 1 ) ) {\n",
    "#                         resolve( urls );\n",
    "#                     }\n",
    "#                 }\n",
    "#             }, 10 );\n",
    "#         } );\n",
    "#     } );\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "#  * Call the main function to grab the URLs and initiate the download\n",
    "#  */\n",
    "# grabUrls().then( function( urls ) {\n",
    "#     urls = urls.join( '\\n' );\n",
    "#     createDownload( urls );\n",
    "# } );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images\r\n"
     ]
    }
   ],
   "source": [
    "!Pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다운로드 폴더에서 urls.txt를 images 디렉토리로 옮겨주기\n",
    "path_to_download_folder = os.path.join(Path.home(), \"downloads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/urls.txt'"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.move(os.path.join(path_to_download_folder,'urls.txt'), os.path.join(os.getcwd(),'urls.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000000.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000001.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000002.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000003.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000004.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000005.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000006.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000007.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000008.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000009.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000010.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000011.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000012.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000013.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000014.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000015.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000016.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000017.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000018.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000019.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000020.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000021.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000022.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000023.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000024.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000025.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000026.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000027.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000028.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000029.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000030.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000031.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000032.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000033.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000034.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000035.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000036.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000037.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000038.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000039.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000040.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000041.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000042.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000043.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000044.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000045.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000046.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000047.jpg\n",
      "[INFO] downloaded: images/asian_woman_in_pink_tshirt/00000048.jpg\n"
     ]
    }
   ],
   "source": [
    "!python download_images.py --urls urls.txt --output images/{class__}\n",
    "\n",
    "# 참고사항: download_images.py 중에 url로 이미지가 다운받아지지 않는 경우에는 자체적으로 이미지를 제거하는 조건문 포함\n",
    "# 참고사항: 이미지 파일명을 오름차순 방식으로 숫자로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm urls.txt #다른 클래스와 겹침 방지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 여기서부터는 수작업\n",
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다수의 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/theAIGuysCode/Download-Google-Images.git\n",
    "%cd Download-Google-Images\n",
    "!pip install -r requirements.txt\n",
    "!mkdir images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many classes do you wish to create for your human detection? 3\n",
      "what is the race of the person? e.g. asian white\n",
      "describe the person. e.g. woman, man, boy, girl, senior ?woman\n",
      "describe the most outstanding color of the persons outfit. e.g. pink brown\n",
      "what ws the outfit? e.g. tshirt lingerie \n",
      "['woman in brown lingerie ']\n",
      "what is the race of the person? e.g. asian asian\n",
      "describe the person. e.g. woman, man, boy, girl, senior ?boy\n",
      "describe the most outstanding color of the persons outfit. e.g. pink red\n",
      "what ws the outfit? e.g. tshirt tshirt\n",
      "['woman in brown lingerie ', 'asian boy in red tshirt']\n",
      "what is the race of the person? e.g. asian black\n",
      "describe the person. e.g. woman, man, boy, girl, senior ?person\n",
      "describe the most outstanding color of the persons outfit. e.g. pink pink\n",
      "what ws the outfit? e.g. tshirt grillz\n",
      "['woman in brown lingerie ', 'asian boy in red tshirt', 'black person in pink grillz']\n"
     ]
    }
   ],
   "source": [
    "# 클래스문 자동 작성 완성\n",
    "classes = []\n",
    "\n",
    "class_count = int(input('how many classes do you wish to create for your human detection? '))\n",
    "\n",
    "for each in range(class_count):\n",
    "    \n",
    "    race = input('what is the race of the person? e.g. asian ')# 주로 백인 위주로 이미지가 검색된다 \n",
    "    gender_and_age = input('describe the person. e.g. woman, man, boy, girl, senior? ') # e.g. man, boy, girl, grandma, senior\n",
    "    color_of_outfit = input('describe the most outstanding color of the persons outfit. e.g. pink ')\n",
    "    type_of_outfit = input('what ws the outfit? e.g. tshirt ') # e.g. top, shirt, jacket, jeans\n",
    "\n",
    "    if race not in ['white', 'caucasian']:\n",
    "        class_ = '{} {} in {} {}'.format(race, gender_and_age, color_of_outfit, type_of_outfit)\n",
    "    else:\n",
    "        class_ = '{} in {} {}'.format(gender_and_age, color_of_outfit, type_of_outfit)\n",
    "    classes.append(class_)\n",
    "    print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_left = classes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'download_images.py': [Errno 2] No such file or directory\n",
      "python: can't open file 'download_images.py': [Errno 2] No such file or directory\n",
      "python: can't open file 'download_images.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# 여기서부턴 한번만 돌리면 된다\n",
    "classes = [re.sub(' ', '_', x.strip()) for x in classes]\n",
    "for each in classes:\n",
    "    if each not in os.listdir():\n",
    "        !mkdir {each}\n",
    "    else:\n",
    "        print('{each} directory already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'urls.txt' in os.listdir(str(os.path.join(Path.home(), \"Downloads\"))):\n",
    "    print('before proceeding, a urls.txt file already exists in your downloads directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 여기서부터는 수작업\n",
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 클래스 개수만큼 자료수집 반복되는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 구글 이미지를 들어간다\n",
    "- 받은 클래스 입력 후 검색\n",
    "- 원하는 이미지 갯수만큼 페이지에 뜨게 아래로 스크롤 (디폴트값으로 구글 이미지에서 스크롤링 안했을때 뜨는 이미지 개수는 100개다)\n",
    "- 개발자 모드 콘솔 탭에서 console.js 한줄 한줄씩 입력 후 urls.txt 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black person in pink grillz\n"
     ]
    }
   ],
   "source": [
    "print(classes_left[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "#  * simulate a right-click event so we can grab the image URL using the\n",
    "#  * context menu alleviating the need to navigate to another page\n",
    "#  *\n",
    "#  * attributed to @jmiserez: http://pyimg.co/9qe7y\n",
    "#  *\n",
    "#  * @param   {object}  element  DOM Element\n",
    "#  *\n",
    "#  * @return  {void}\n",
    "#  */\n",
    "# function simulateRightClick( element ) {\n",
    "#     var event1 = new MouseEvent( 'mousedown', {\n",
    "#         bubbles: true,\n",
    "#         cancelable: false,\n",
    "#         view: window,\n",
    "#         button: 2,\n",
    "#         buttons: 2,\n",
    "#         clientX: element.getBoundingClientRect().x,\n",
    "#         clientY: element.getBoundingClientRect().y\n",
    "#     } );\n",
    "#     element.dispatchEvent( event1 );\n",
    "#     var event2 = new MouseEvent( 'mouseup', {\n",
    "#         bubbles: true,\n",
    "#         cancelable: false,\n",
    "#         view: window,\n",
    "#         button: 2,\n",
    "#         buttons: 0,\n",
    "#         clientX: element.getBoundingClientRect().x,\n",
    "#         clientY: element.getBoundingClientRect().y\n",
    "#     } );\n",
    "#     element.dispatchEvent( event2 );\n",
    "#     var event3 = new MouseEvent( 'contextmenu', {\n",
    "#         bubbles: true,\n",
    "#         cancelable: false,\n",
    "#         view: window,\n",
    "#         button: 2,\n",
    "#         buttons: 0,\n",
    "#         clientX: element.getBoundingClientRect().x,\n",
    "#         clientY: element.getBoundingClientRect().y\n",
    "#     } );\n",
    "#     element.dispatchEvent( event3 );\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "#  * grabs a URL Parameter from a query string because Google Images\n",
    "#  * stores the full image URL in a query parameter\n",
    "#  *\n",
    "#  * @param   {string}  queryString  The Query String\n",
    "#  * @param   {string}  key          The key to grab a value for\n",
    "#  *\n",
    "#  * @return  {string}               value\n",
    "#  */\n",
    "# function getURLParam( queryString, key ) {\n",
    "#     var vars = queryString.replace( /^\\?/, '' ).split( '&' );\n",
    "#     for ( let i = 0; i < vars.length; i++ ) {\n",
    "#         let pair = vars[ i ].split( '=' );\n",
    "#         if ( pair[0] == key ) {\n",
    "#             return pair[1];\n",
    "#         }\n",
    "#     }\n",
    "#     return false;\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "#  * Generate and automatically download a txt file from the URL contents\n",
    "#  *\n",
    "#  * @param   {string}  contents  The contents to download\n",
    "#  *\n",
    "#  * @return  {void}\n",
    "#  */\n",
    "# function createDownload( contents ) {\n",
    "#     var hiddenElement = document.createElement( 'a' );\n",
    "#     hiddenElement.href = 'data:attachment/text,' + encodeURI( contents );\n",
    "#     hiddenElement.target = '_blank';\n",
    "#     hiddenElement.download = 'urls.txt';\n",
    "#     hiddenElement.click();\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "#  * grab all URLs va a Promise that resolves once all URLs have been\n",
    "#  * acquired\n",
    "#  *\n",
    "#  * @return  {object}  Promise object\n",
    "#  */\n",
    "# function grabUrls() {\n",
    "#     var urls = [];\n",
    "#     return new Promise( function( resolve, reject ) {\n",
    "#         var count = document.querySelectorAll(\n",
    "#         \t'.isv-r a:first-of-type' ).length,\n",
    "#             index = 0;\n",
    "#         Array.prototype.forEach.call( document.querySelectorAll(\n",
    "#         \t'.isv-r a:first-of-type' ), function( element ) {\n",
    "#             // using the right click menu Google will generate the\n",
    "#             // full-size URL; won't work in Internet Explorer\n",
    "#             // (http://pyimg.co/byukr)\n",
    "#             simulateRightClick( element.querySelector( ':scope img' ) );\n",
    "#             // Wait for it to appear on the <a> element\n",
    "#             var interval = setInterval( function() {\n",
    "#                 if ( element.href.trim() !== '' ) {\n",
    "#                     clearInterval( interval );\n",
    "#                     // extract the full-size version of the image\n",
    "#                     let googleUrl = element.href.replace( /.*(\\?)/, '$1' ),\n",
    "#                         fullImageUrl = decodeURIComponent(\n",
    "#                         \tgetURLParam( googleUrl, 'imgurl' ) );\n",
    "#                     if ( fullImageUrl !== 'false' ) {\n",
    "#                         urls.push( fullImageUrl );\n",
    "#                     }\n",
    "#                     // sometimes the URL returns a \"false\" string and\n",
    "#                     // we still want to count those so our Promise\n",
    "#                     // resolves\n",
    "#                     index++;\n",
    "#                     if ( index == ( count - 1 ) ) {\n",
    "#                         resolve( urls );\n",
    "#                     }\n",
    "#                 }\n",
    "#             }, 10 );\n",
    "#         } );\n",
    "#     } );\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**\n",
    "#  * Call the main function to grab the URLs and initiate the download\n",
    "#  */\n",
    "# grabUrls().then( function( urls ) {\n",
    "#     urls = urls.join( '\\n' );\n",
    "#     createDownload( urls );\n",
    "# } );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다운로드 폴더에서 urls.txt를 images 디렉토리로 옮겨주기\n",
    "%cd images\n",
    "path_to_download_folder = str(os.path.join(Path.home(), \"Downloads\"))\n",
    "shutil.move(path_to_download_folder+'/urls.txt', os.getcwd()+'/{classes_left[0]}/urls.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python download_images.py --urls images/{classes_left[0]}/urls.txt --output images/{classes_left[0]}\n",
    "!rm images/{classes_left[0]}/urls.txt #다른 클래스와 겹침 방지\n",
    "\n",
    "# 참고사항: download_images.py 중에 url로 이미지가 다운받아지지 않는 경우에는 자체적으로 이미지를 제거하는 조건문 포함\n",
    "# 참고사항: 이미지 파일명을 오름차순 방식으로 숫자로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['black person in pink grillz']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다음 클래스 표시\n",
    "classes_left.pop(0)\n",
    "print(classes_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your next class is: \n",
      " black person in pink grillz\n"
     ]
    }
   ],
   "source": [
    "# classes_left가 더이상 뜨지 않을때까지 4.1.2.1 과정 반복\n",
    "print('your next class is: \\n {}'.format(classes_left[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'labelImg'에 복제합니다...\n",
      "remote: Enumerating objects: 1697, done.\u001b[K\n",
      "remote: Total 1697 (delta 0), reused 0 (delta 0), pack-reused 1697\u001b[K\n",
      "오브젝트를 받는 중: 100% (1697/1697), 232.71 MiB | 17.77 MiB/s, 완료.\n",
      "델타를 알아내는 중: 100% (1013/1013), 완료.\n"
     ]
    }
   ],
   "source": [
    "# 수동 라벨링 GUI 모듈 다운로드: 이미 설치되어 있다면 해당 부분은 스킵해도 된다 \n",
    "\n",
    "!git clone https://github.com/tzutalin/labelImg.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/labelImg\n"
     ]
    }
   ],
   "source": [
    "%cd labelImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyqt5 in /Users/dy/opt/anaconda3/lib/python3.7/site-packages (5.15.2)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.8 in /Users/dy/opt/anaconda3/lib/python3.7/site-packages (from pyqt5) (12.8.1)\n",
      "Requirement already satisfied: lxml in /Users/dy/opt/anaconda3/lib/python3.7/site-packages (4.5.0)\n"
     ]
    }
   ],
   "source": [
    "# 이미 설치가 되어 있다면 해당 부분은 스킵해도 된다\n",
    "\n",
    "!pip install pyqt5\n",
    "!pip install lxml\n",
    "!pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모듈 지원 파일\n",
    "- obj.names\n",
    "- obj.data\n",
    "- cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/labelImg\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes.txt 파일 생성 후 클래스 작성 \n",
    "classes_text = open(r'classes.txt', 'w')\n",
    "try:\n",
    "    for x in classes:\n",
    "        x = re.sub('_', ' ', x)\n",
    "        x += '\\n'\n",
    "        classes_text.write(x)\n",
    "    classes_text.close()\n",
    "except:\n",
    "    x = class_ +'\\n'\n",
    "    classes_text.write(x)\n",
    "    classes_text.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! 백업 위치를 로컬로 바꿔야할까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(r'data.txt', 'w')\n",
    "try:\n",
    "    num = len(classes)\n",
    "    data.write('classes = {}\\ntrain = data/train.txt\\nvalid = data/test.txt\\nnames = data/obj.names\\nbackup = /mydrive/yolov4/backup'.format(num))\n",
    "    data.close()\n",
    "\n",
    "except:\n",
    "    data.write('classes = 1\\ntrain = data/train.txt\\nvalid = data/test.txt\\nnames = data/obj.names\\nbackup = /mydrive/yolov4/backup')\n",
    "    data.close()\n",
    "os.rename('data.txt', 'obj.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라벨링 방법:\n",
    "    - create\\nRectBox 버튼 클릭\n",
    "    - 드래그해서 관심영역을 표시 후 적합한 라벨을 클릭한다\n",
    "    - 저장하기 이전에 PASCAL VOC를 눌러서 라벨링 형식을 YOLO format으로 적용한다\n",
    "    - 저장 후 다음 이미지로 넘어간다\n",
    "\n",
    "- 참고사항: 적합성이 떨어지는 이미지는 라벨링 작업을 하지 않고 스킵한다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/labelImg\n"
     ]
    }
   ],
   "source": [
    "%cd labelImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('asian woman in pink tshirt', [(106, 221), (870, 221), (870, 1428), (106, 1428)], None, None, False)]\n",
      "[('asian woman in pink tshirt', [(106, 221), (870, 221), (870, 1428), (106, 1428)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000000.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000000.xml\n",
      "[('asian woman in pink tshirt', [(152, 160), (877, 160), (877, 1597), (152, 1597)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000001.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000001.xml\n",
      "[('asian woman in pink tshirt', [(462, 47), (1202, 47), (1202, 1300), (462, 1300)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000002.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000002.xml\n",
      "[('asian woman in pink tshirt', [(624, 24), (1235, 24), (1235, 867), (624, 867)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000003.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000003.xml\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000003.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000003.xml\n",
      "[('asian woman in pink tshirt', [(364, 149), (875, 149), (875, 1608), (364, 1608)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000004.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000004.xml\n",
      "[('asian woman in pink tshirt', [(185, 195), (672, 195), (672, 879), (185, 879)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000005.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000005.xml\n",
      "[('asian woman in pink tshirt', [(109, 65), (359, 65), (359, 416), (109, 416)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000006.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000006.xml\n",
      "[('asian woman in pink tshirt', [(226, 93), (628, 93), (628, 1139), (226, 1139)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000007.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000007.xml\n",
      "[('asian woman in pink tshirt', [(213, 29), (607, 29), (607, 417), (213, 417)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000008.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000008.xml\n",
      "[('asian woman in pink tshirt', [(256, 68), (708, 68), (708, 1297), (256, 1297)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000009.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000009.xml\n",
      "[('asian woman in pink tshirt', [(344, 64), (761, 64), (761, 1261), (344, 1261)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000010.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000010.xml\n",
      "[('asian woman in pink tshirt', [(345, 246), (643, 246), (643, 1263), (345, 1263)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000013.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000013.xml\n",
      "[('asian woman in pink tshirt', [(24, 0), (179, 0), (179, 330), (24, 330)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000016.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000016.xml\n",
      "[('asian woman in pink tshirt', [(50, 42), (534, 42), (534, 584), (50, 584)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000017.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000017.xml\n",
      "[('asian woman in pink tshirt', [(99, 47), (619, 47), (619, 1299), (99, 1299)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000018.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000018.xml\n",
      "[('asian woman in pink tshirt', [(606, 90), (1523, 90), (1523, 1207), (606, 1207)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000019.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000019.xml\n",
      "[('asian woman in pink tshirt', [(318, 231), (883, 231), (883, 1476), (318, 1476)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000020.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000020.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('asian woman in pink tshirt', [(76, 70), (688, 70), (688, 1284), (76, 1284)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000021.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000021.xml\n",
      "[('asian woman in pink tshirt', [(780, 306), (1155, 306), (1155, 972), (780, 972)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000022.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000022.xml\n",
      "[('asian woman in pink tshirt', [(939, 36), (1391, 36), (1391, 430), (939, 430)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000024.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000024.xml\n",
      "[('asian woman in pink tshirt', [(1632, 33), (3052, 33), (3052, 2159), (1632, 2159)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000025.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000025.xml\n",
      "[('asian woman in pink tshirt', [(339, 41), (470, 41), (470, 322), (339, 322)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000026.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000026.xml\n",
      "[('asian woman in pink tshirt', [(57, 49), (291, 49), (291, 298), (57, 298)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000027.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000027.xml\n",
      "[('asian woman in pink tshirt', [(384, 49), (702, 49), (702, 533), (384, 533)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000028.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000028.xml\n",
      "[('asian woman in pink tshirt', [(8, 0), (1035, 0), (1035, 1004), (8, 1004)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000029.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000029.xml\n",
      "[('asian woman in pink tshirt', [(254, 53), (481, 53), (481, 300), (254, 300)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000030.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000030.xml\n",
      "[('asian woman in pink tshirt', [(105, 45), (511, 45), (511, 1024), (105, 1024)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000031.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000031.xml\n",
      "[('asian woman in pink tshirt', [(641, 28), (1400, 28), (1400, 1063), (641, 1063)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000032.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000032.xml\n",
      "[('asian woman in pink tshirt', [(77, 86), (780, 86), (780, 1066), (77, 1066)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000033.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000033.xml\n",
      "[('asian woman in pink tshirt', [(5, 8), (374, 8), (374, 813), (5, 813)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000034.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000034.xml\n",
      "[('asian woman in pink tshirt', [(404, 0), (711, 0), (711, 244), (404, 244)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000035.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000035.xml\n",
      "[('asian woman in pink tshirt', [(257, 149), (562, 149), (562, 1179), (257, 1179)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000036.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000036.xml\n",
      "[('asian woman in pink tshirt', [(409, 89), (1201, 89), (1201, 1002), (409, 1002)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000038.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000038.xml\n",
      "[('asian woman in pink tshirt', [(612, 1963), (3435, 1963), (3435, 5472), (612, 5472)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000040.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000040.xml\n",
      "[('asian woman in pink tshirt', [(151, 62), (344, 62), (344, 300), (151, 300)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000041.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000041.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('asian woman in pink tshirt', [(100, 39), (578, 39), (578, 417), (100, 417)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000042.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000042.xml\n",
      "[('asian woman in pink tshirt', [(23, 67), (250, 67), (250, 411), (23, 411)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000043.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000043.xml\n",
      "[('asian woman in pink tshirt', [(363, 48), (730, 48), (730, 516), (363, 516)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000046.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000046.xml\n",
      "[('asian woman in pink tshirt', [(1034, 50), (1555, 50), (1555, 1011), (1034, 1011)], None, None, False)]\n",
      "Image:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000048.jpg -> Annotation:/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt/00000048.xml\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    classes_left = classes.copy()\n",
    "except:\n",
    "    !python labelImg.py ../images/{class__} classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     !python labelImg.py ../images/{classes_left[0]} classes.txt\n",
    "#     classes_left.pop(0)\n",
    "# else:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking\n",
      "[Errno 2] No such file or directory: 'images'\n",
      "/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking\n"
     ]
    }
   ],
   "source": [
    "%cd {'..'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images\n"
     ]
    }
   ],
   "source": [
    "%cd images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/asian_woman_in_pink_tshirt\n",
      "/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images\n"
     ]
    }
   ],
   "source": [
    "# 스킵된 이미지 삭제\n",
    "\n",
    "try:\n",
    "    for x in classes:\n",
    "        %cd {x}\n",
    "        txt_list = glob.glob('*.txt')\n",
    "        jpg_list = [re.sub('.txt', '.jpg', each) for each in txt_list]\n",
    "\n",
    "        whole_list = txt_list + jpg_list\n",
    "\n",
    "        for file in os.listdir():\n",
    "            if file not in whole_list:\n",
    "                !rm {file}\n",
    "        %cd {'..'}\n",
    "\n",
    "except: \n",
    "    %cd {class__}\n",
    "    txt_list = glob.glob('*.txt')\n",
    "    jpg_list = [re.sub('.txt', '.jpg', each) for each in txt_list]\n",
    "\n",
    "    whole_list = txt_list + jpg_list\n",
    "\n",
    "    for file in os.listdir():\n",
    "        if file not in whole_list:\n",
    "            !rm {file}\n",
    "    %cd {'..'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename('classes.txt', 'obj.names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg 파일 생성\n",
    "cfg_txt = open('yolov4-obj.txt', 'w')\n",
    "list_of_lines = ['[net]\\n', '# Testing\\n', '#batch=1\\n', '#subdivisions=1\\n', '# Training\\n', 'batch=64\\n', 'subdivisions=16\\n', 'width=416\\n', 'height=416\\n', 'channels=3\\n', 'momentum=0.949\\n', 'decay=0.0005\\n', 'angle=0\\n', 'saturation = 1.5\\n', 'exposure = 1.5\\n', 'hue=.1\\n', '\\n', 'learning_rate=0.001\\n', 'burn_in=1000\\n', 'max_batches = 6000\\n', 'policy=steps\\n', 'steps=4800,5400\\n', 'scales=.1,.1\\n', '\\n', '#cutmix=1\\n', 'mosaic=1\\n', '\\n', '#:104x104 54:52x52 85:26x26 104:13x13 for 416\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=32\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '# Downsample\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=64\\n', 'size=3\\n', 'stride=2\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=64\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[route]\\n', 'layers = -2\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=64\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=32\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=64\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=64\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[route]\\n', 'layers = -1,-7\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=64\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '# Downsample\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=3\\n', 'stride=2\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=64\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[route]\\n', 'layers = -2\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=64\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=64\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=64\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=64\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=64\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=64\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[route]\\n', 'layers = -1,-10\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '# Downsample\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=3\\n', 'stride=2\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[route]\\n', 'layers = -2\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[route]\\n', 'layers = -1,-28\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '# Downsample\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=3\\n', 'stride=2\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[route]\\n', 'layers = -2\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[route]\\n', 'layers = -1,-28\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '# Downsample\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=1024\\n', 'size=3\\n', 'stride=2\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[route]\\n', 'layers = -2\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[shortcut]\\n', 'from=-3\\n', 'activation=linear\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', '\\n', '[route]\\n', 'layers = -1,-16\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=1024\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=mish\\n', 'stopbackward=800\\n', '\\n', '##########################\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'filters=1024\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '### SPP ###\\n', '[maxpool]\\n', 'stride=1\\n', 'size=5\\n', '\\n', '[route]\\n', 'layers=-2\\n', '\\n', '[maxpool]\\n', 'stride=1\\n', 'size=9\\n', '\\n', '[route]\\n', 'layers=-4\\n', '\\n', '[maxpool]\\n', 'stride=1\\n', 'size=13\\n', '\\n', '[route]\\n', 'layers=-1,-3,-5,-6\\n', '### End SPP ###\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'filters=1024\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[upsample]\\n', 'stride=2\\n', '\\n', '[route]\\n', 'layers = 85\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[route]\\n', 'layers = -1, -3\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'filters=512\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'filters=512\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[upsample]\\n', 'stride=2\\n', '\\n', '[route]\\n', 'layers = 54\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[route]\\n', 'layers = -1, -3\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'filters=256\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'filters=256\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=128\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '##########################\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'filters=256\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'filters=18\\n', 'activation=linear\\n', '\\n', '\\n', '[yolo]\\n', 'mask = 0,1,2\\n', 'anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\\n', 'classes=1\\n', 'num=9\\n', 'jitter=.3\\n', 'ignore_thresh = .7\\n', 'truth_thresh = 1\\n', 'scale_x_y = 1.2\\n', 'iou_thresh=0.213\\n', 'cls_normalizer=1.0\\n', 'iou_normalizer=0.07\\n', 'iou_loss=ciou\\n', 'nms_kind=greedynms\\n', 'beta_nms=0.6\\n', 'max_delta=5\\n', '\\n', '\\n', '[route]\\n', 'layers = -4\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'size=3\\n', 'stride=2\\n', 'pad=1\\n', 'filters=256\\n', 'activation=leaky\\n', '\\n', '[route]\\n', 'layers = -1, -16\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'filters=512\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'filters=512\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=256\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'filters=512\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'filters=18\\n', 'activation=linear\\n', '\\n', '\\n', '[yolo]\\n', 'mask = 3,4,5\\n', 'anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\\n', 'classes=1\\n', 'num=9\\n', 'jitter=.3\\n', 'ignore_thresh = .7\\n', 'truth_thresh = 1\\n', 'scale_x_y = 1.1\\n', 'iou_thresh=0.213\\n', 'cls_normalizer=1.0\\n', 'iou_normalizer=0.07\\n', 'iou_loss=ciou\\n', 'nms_kind=greedynms\\n', 'beta_nms=0.6\\n', 'max_delta=5\\n', '\\n', '\\n', '[route]\\n', 'layers = -4\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'size=3\\n', 'stride=2\\n', 'pad=1\\n', 'filters=512\\n', 'activation=leaky\\n', '\\n', '[route]\\n', 'layers = -1, -37\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'filters=1024\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'filters=1024\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'filters=512\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'batch_normalize=1\\n', 'size=3\\n', 'stride=1\\n', 'pad=1\\n', 'filters=1024\\n', 'activation=leaky\\n', '\\n', '[convolutional]\\n', 'size=1\\n', 'stride=1\\n', 'pad=1\\n', 'filters=18\\n', 'activation=linear\\n', '\\n', '\\n', '[yolo]\\n', 'mask = 6,7,8\\n', 'anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\\n', 'classes=1\\n', 'num=9\\n', 'jitter=.3\\n', 'ignore_thresh = .7\\n', 'truth_thresh = 1\\n', 'random=1\\n', 'scale_x_y = 1.05\\n', 'iou_thresh=0.213\\n', 'cls_normalizer=1.0\\n', 'iou_normalizer=0.07\\n', 'iou_loss=ciou\\n', 'nms_kind=greedynms\\n', 'beta_nms=0.6\\n', 'max_delta=5\\n', '\\n']\n",
    "cfg_txt.writelines(list_of_lines)\n",
    "cfg_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg 파일 수정\n",
    "cfg_txt = open('yolov4-obj.txt', \"r\")\n",
    "list_of_lines = cfg_txt.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing\n",
    "# list_of_lines[2] = 'batch=1'\n",
    "# list_of_lines[3] = 'subdivisions=1'\n",
    "# list_of_lines[5] = '#batch=64'\n",
    "# list_of_lines[6] = '#subdivisions=16'\n",
    "\n",
    "#training\n",
    "list_of_lines[2] = '#batch=1'\n",
    "list_of_lines[3] = '#subdivisions=1'\n",
    "list_of_lines[5] = 'batch=64'\n",
    "list_of_lines[6] = 'subdivisions=16'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes, filters\n",
    "try:\n",
    "    classes_count = len(classes)\n",
    "except:\n",
    "    classes_count = 1\n",
    "\n",
    "filters = (classes_count+5)*3\n",
    "\n",
    "list_of_lines[962] = 'filters={}'.format(filters)\n",
    "list_of_lines[969] = 'classes={}'.format(classes_count)\n",
    "\n",
    "list_of_lines[1050] = 'filters={}'.format(filters)\n",
    "list_of_lines[1057] = 'classes={}'.format(classes_count)\n",
    "\n",
    "list_of_lines[1138] = 'filters={}'.format(filters)\n",
    "list_of_lines[1145] = 'classes={}'.format(classes_count)\n",
    "\n",
    "# width, height\n",
    "width, height = 416, 416\n",
    "list_of_lines[7] = 'width = {}'.format(width)\n",
    "list_of_lines[8] = 'height = {}'.format(height)\n",
    "\n",
    "# max_batches, steps\n",
    "if classes_count >=3:\n",
    "    max_batches = classes_count*2000 # no. of classes * 2000, min 6000\n",
    "else:\n",
    "    max_batches = 6000\n",
    "\n",
    "steps1, steps2 = np.round(0.8*max_batches), np.round(0.9*max_batches)\n",
    "\n",
    "list_of_lines[19] = 'max_batches = {}'.format(max_batches)\n",
    "list_of_lines[20] = 'steps = {}, {}'.format(steps1, steps2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open('yolov4-obj.txt', \"w\")\n",
    "a_file.writelines(list_of_lines)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename('yolov4-obj.txt', 'yolov4-obj.cfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## obj & test 디렉토리로 자료 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    !mkdir obj\n",
    "    !mkdir test\n",
    "except:\n",
    "    print('directories already exist')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기서 train만 시킬건지 validation dataset도 만들건지 선택\n",
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train 데이터만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter valid size (between 0~1)0.8\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/{each}'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-195-313bb6373396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/{each}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain_count\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvalid_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/{each}'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for each in classes:\n",
    "        path = os.path.join(os.getcwd(),each)\n",
    "        jpg_files = [file for file in os.listdir(path) if file.endswith('.jpg')]\n",
    "        txt_files = [re.sub('.jpg', '.txt', file) for file in jpg_files]\n",
    "\n",
    "        train_count  = len(jpg_files)\n",
    "        rndnums = list(random.sample(range(0, len(jpg_files)), len(jpg_files)))\n",
    "\n",
    "        train_file_index = rndnums[0:int(train_count)+1]\n",
    "        train_file_name = [jpg_files[i] for i in train_file_index]\n",
    "        train_file_name.extend([txt_files[i] for i in train_file_index])\n",
    "\n",
    "        # train_files\n",
    "        for x in train_file_name:\n",
    "            shutil.copyfile(os.path.join(path, x), os.path.join(os.getcwd(), 'obj/{x}'))\n",
    "\n",
    "except:\n",
    "    path = os.path.join(os.getcwd(),class__)\n",
    "    jpg_files = [file for file in os.listdir(path) if file.endswith('.jpg')]\n",
    "    txt_files = [re.sub('.jpg', '.txt', file) for file in jpg_files]\n",
    "\n",
    "    train_count  = len(jpg_files)\n",
    "    rndnums = list(random.sample(range(0, len(files)), len(files)))\n",
    "\n",
    "    train_file_index = rndnums[0:int(train_count)+1]\n",
    "    train_file_name = [jpg_files[i] for i in train_file_index]\n",
    "    train_file_name.extend([txt_files[i] for i in train_file_index])\n",
    "\n",
    "    # train_files\n",
    "    for x in train_file_name:\n",
    "        shutil.copyfile(os.path.join(path, x), os.path.join(os.getcwd(), 'obj/{x}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-215-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train & validation 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images'"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34masian_woman_in_pink_tshirt\u001b[m\u001b[m obj.names\r\n",
      "\u001b[34mobj\u001b[m\u001b[m                        \u001b[34mtest\u001b[m\u001b[m\r\n",
      "obj.data                   yolov4-obj.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_size = float(input('enter valid size (between 0~1)\\n'))\n",
    "test_size = 0.2\n",
    "train_size = 1-test_size\n",
    "\n",
    "obj = os.path.join(os.getcwd(), 'obj')\n",
    "test = os.path.join(os.getcwd(), 'test')\n",
    "\n",
    "try:\n",
    "    for each in classes:\n",
    "        path = os.path.join(os.getcwd(),each)\n",
    "        jpg_files = [file for file in os.listdir(path) if file.endswith('.jpg')]\n",
    "        txt_files = [re.sub('.jpg', '.txt', file) for file in jpg_files]\n",
    "\n",
    "        train_count  = np.round(train_size*len(jpg_files))\n",
    "        rndnums = list(random.sample(range(0, len(jpg_files)), len(jpg_files)))\n",
    "\n",
    "        train_file_index = rndnums[0:int(train_count)+1]\n",
    "        train_file_name = [jpg_files[i] for i in train_file_index]\n",
    "        train_file_name.extend([txt_files[i] for i in train_file_index])\n",
    "\n",
    "        valid_file_index = rndnums[int(train_count)+1:]\n",
    "        valid_file_name = [jpg_files[i] for i in valid_file_index]\n",
    "        valid_file_name.extend([txt_files[i] for i in valid_file_index])\n",
    "\n",
    "        # train_files\n",
    "        for x in train_file_name:\n",
    "            shutil.copyfile(os.path.join(path, x), os.path.join(os.getcwd(), 'obj/{x}'))\n",
    "\n",
    "        # valid_files\n",
    "        for z in valid_file_name:\n",
    "            shutil.copyfile(os.path.join(path, z), os.path.join(os.getcwd(), 'test/{z}'))\n",
    "\n",
    "except:\n",
    "    path = os.path.join(os.getcwd(),class__)\n",
    "    jpg_files = [file for file in os.listdir(path) if file.endswith('.jpg')]\n",
    "    txt_files = [re.sub('.jpg', '.txt', file) for file in jpg_files]\n",
    "\n",
    "    train_count  = np.round(train_size*len(jpg_files))\n",
    "    rndnums = list(random.sample(range(0, len(jpg_files)), len(jpg_files)))\n",
    "\n",
    "    train_file_index = rndnums[0:int(train_count)+1]\n",
    "    train_file_name = [jpg_files[i] for i in train_file_index]\n",
    "    train_file_name.extend([txt_files[i] for i in train_file_index])\n",
    "\n",
    "    valid_file_index = rndnums[int(train_count)+1:]\n",
    "    valid_file_name = [jpg_files[i] for i in valid_file_index]\n",
    "    valid_file_name.extend([txt_files[i] for i in valid_file_index])\n",
    "\n",
    "    # train_files\n",
    "    for x in train_file_name:\n",
    "        shutil.copyfile(os.path.join(path, x), os.path.join(obj, '{}'.format(x)))\n",
    "\n",
    "    # valid_files\n",
    "    for z in valid_file_name:\n",
    "        shutil.copyfile(os.path.join(path, z), os.path.join(test, '{}'.format(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34masian_woman_in_pink_tshirt\u001b[m\u001b[m obj.data\r\n",
      "\u001b[34mdata\u001b[m\u001b[m                       obj.names\r\n",
      "images.zip                 \u001b[34mtest\u001b[m\u001b[m\r\n",
      "\u001b[34mobj\u001b[m\u001b[m                        yolov4-obj.cfg\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in ['obj.data', 'obj.names', 'yolov4-obj.cfg', 'obj', 'test']:\n",
    "    shutil.move(os.path.join(os.getcwd(),each), os.path.join(os.getcwd(), 'data', each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dy/Documents/dss14/dss_workspace/project/deep_learning_projects/deeplearning-repo-1/human_tracking/Download-Google-Images/images/objs.zip'"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.make_archive(\"objs\",\"zip\", os.path.join(os.getcwd(), 'data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv4 Object Detector w/ Darknet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구글콜랩 주소 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 마치며"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !YOLO vs CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능차이 원인에 대한 궁금증이 생겼다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !시행착오 과정\n",
    "\n",
    "- 깃헙에서 theAIGuysCode 참조:\n",
    "    - https://github.com/theAIGuysCode/Download-Google-Images\n",
    "    > 클래스별로 이미 라벨링된 이미지 데이터셋을 가져와서 학습시켜봤으나 클래스가 구체적인 특징을 갖지 않아서 recall 수치가 떨어짐\n",
    "    \n",
    "    - 보완: 구체적인 특징을 가진 이미지 직접 라벨링 후 학습 데이터로 사용\n",
    "    > 몇가지 질문으로 인물의 특징을 가지고 구글 이미지에서 학습할 수 있는 이미지 자료를 가져와서https://github.com/tzutalin/labelImg 에서 제공하는 라벨링 툴을 이용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "인상착의 입력해서 OIDv6 데이터셋을 사용해본 결과 recall이 매우 저조 \n",
    "-> 직접 입력해서 직접 라벨링 하는 방식으로 수정\n",
    "\n",
    "google images에서 자동으로 검색어 입력 후 검색\n",
    "검색된 이미지 최대 x개까지 퍼오는 기능 구현\n",
    "라벨링 툴 불러와서 수동 라벨링 진행\n",
    "(라벨링 yolo 학습모델에 맞게 좌표 변환 후 txt 파일로 자동 저장)\n",
    "\n",
    "기존 데이터가 들어 있는 디렉토리들 (obj & test)와 통합\n",
    "generate_train\n",
    "generate_test\n",
    "\n",
    "욜로 모델에 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - https://github.com/theAIGuysCode/Download-Google-Images.git에서 제공하는 download_images.py 모듈로 구글 이미지 다운로드\n",
    "# - 클래스가 여러개인 경우 images 디렉토리에서 클래스별로 디렉토리 만들어주고 라벨링 툴 매번 새로 열어줘야함\n",
    "\n",
    "# - 1차 보완: 한 폴더에서 여러개의 클래스를 누적변경되게 download_images.py의 line 17부터 total 객체 생성 코드 수정\n",
    "\n",
    "# try:\n",
    "#     total = len(os.listdir(args['output']))\n",
    "# except ExplicitException:\n",
    "#     try:\n",
    "#         pwd_ = os.getcwd()\n",
    "#         total = len(os.listdir(pwd_ + re.sub('./', '', args.output))\n",
    "#     except ExplicitException:\n",
    "#         try:\n",
    "#             pwd_ = os.getcwd()\n",
    "#             pwd_ = '/'.join(pwd_.split('/')[:-1])\n",
    "#             total = len(os.listdir(pwd_ + re.sub('../', '', args.output))\n",
    "#         except:\n",
    "#             print('enter the whole correct output path')\n",
    "\n",
    "# - 그러나 자료의 분류가 불가능해서 동일한 특징을 가진 다른 인물을 찾기 위해서 데이터를 학습시킬때 구글 이미지에서 또 크롤링해야하는 번거로움 발생\n",
    "\n",
    "# - 2차 보완: download_images.py 원상태 복구 후 클래스별로 디렉토리 생성해주고 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 독자들에게 질문을 남겨도 되겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'download_images.py': [Errno 2] No such file or directory\n",
      "python: can't open file 'download_images.py': [Errno 2] No such file or directory\n",
      "python: can't open file 'download_images.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# 여기서부턴 한번만 돌리면 된다\n",
    "classes = [re.sub(' ', '_', x.strip()) for x in classes]\n",
    "for each in classes:\n",
    "    if each not in os.listdir():\n",
    "        !mkdir {each}\n",
    "        !python download_images.py --urls images/{each}/urls.txt --output images/{each}\n",
    "    else:\n",
    "        print('{each} directory already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Steps to perform:\n",
    "\n",
    "Query your intended Google search\n",
    "Scroll down through images until they become unrelated to your query or until you've passed enough images for your dataset\n",
    "Right click and hit \"Inspect\" and then navigate to \"Console\" tab\n",
    "One by one enter the lines from console.js into the console window and run them\n",
    "Move urls.txt from Downloads folder to Download-Google-Images folder\n",
    "Create an \"images\" folder where your images will be downloaded\n",
    "Run follwing two python commands as follows:\n",
    "pip install -r requirements.txt\n",
    "python download_images.py --urls urls.txt --output images\n",
    "You should now have all your images inside your images folder!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사이트에 뜬 구글 이미지 url 셀레니움으로 자동 크롤링 모듈 생성: 미완성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀레니움으로 구글 이미지 서치란에 찾고 검색어 입력 후 클릭 \n",
    "# 이미지를 퍼오고 싶은 만큼 (횟수 혹은 시간초) 페이지를 아래로 스크롤하는 명령 입력 (스크롤링 타이머 혹은 양 측정 결과 얼만큼의 이미지가 퍼와지더라도 쓸것)\n",
    "# 오른쪽 클릭 눌러서 inspect 클릭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dy/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: use options instead of chrome_options\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# 콘솔탭 클릭해서 하단 입력란에 마지막 쿼리문까지 한줄씩 입력 후 엔터\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "url = 'https://www.youtube.com/watch?v=EGQyDla8JNU&t=599s'\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\");\n",
    "options.add_argument(\"disable-infobars\");\n",
    "options.add_argument(\"--disable-notifications\");\n",
    "options.add_argument(\"--auto-open-devtools-for-tabs\");\n",
    "\n",
    "driver = webdriver.Chrome(executable_path='./chromedriver', chrome_options=options)\n",
    "driver.get(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver_manager\n",
      "  Downloading webdriver_manager-3.2.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting configparser\n",
      "  Downloading configparser-5.0.1-py3-none-any.whl (22 kB)\n",
      "Collecting crayons\n",
      "  Downloading crayons-0.4.0-py2.py3-none-any.whl (4.6 kB)\n",
      "Requirement already satisfied: requests in /Users/dy/opt/anaconda3/lib/python3.7/site-packages (from webdriver_manager) (2.22.0)\n",
      "Requirement already satisfied: colorama in /Users/dy/opt/anaconda3/lib/python3.7/site-packages (from crayons->webdriver_manager) (0.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dy/opt/anaconda3/lib/python3.7/site-packages (from requests->webdriver_manager) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/dy/opt/anaconda3/lib/python3.7/site-packages (from requests->webdriver_manager) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/dy/opt/anaconda3/lib/python3.7/site-packages (from requests->webdriver_manager) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/dy/opt/anaconda3/lib/python3.7/site-packages (from requests->webdriver_manager) (1.25.8)\n",
      "Installing collected packages: configparser, crayons, webdriver-manager\n",
      "Successfully installed configparser-5.0.1 crayons-0.4.0 webdriver-manager-3.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 87.0.4280\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n",
      "[WDM] - Driver [/Users/dy/.wdm/drivers/chromedriver/mac64/87.0.4280.88/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-5a030c8f3e3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChromeOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--remote-debugging-port=8889'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mChromeDriverManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchrome_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0mremote_server_addr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     keep_alive=keep_alive),\n\u001b[0;32m---> 81\u001b[0;31m                 desired_capabilities=desired_capabilities)\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001b[0m\n\u001b[1;32m    155\u001b[0m             warnings.warn(\"Please use FirefoxOptions to set browser profile\",\n\u001b[1;32m    156\u001b[0m                           DeprecationWarning, stacklevel=2)\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrowser_profile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSwitchTo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mobile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMobile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[0;34m(self, capabilities, browser_profile)\u001b[0m\n\u001b[1;32m    250\u001b[0m         parameters = {\"capabilities\": w3c_caps,\n\u001b[1;32m    251\u001b[0m                       \"desiredCapabilities\": capabilities}\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'sessionId'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: chrome not reachable\n"
     ]
    }
   ],
   "source": [
    "# 크롬드라이버 자동 업데이트 모듈\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--remote-debugging-port=8889')\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install(), chrome_options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pychrome\n",
    "dev_tools = pychrome.Browser(url='http://localhost:8889')\n",
    "dev_tools.list_tab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pychrome\n",
    "dev_tools = pychrome.Browser(url='http://localhost:8889')\n",
    "tab = dev_tools.list_tab()[0]\n",
    "tab.start()\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "# tab.call_method('Network.emulateNetworkConditions',\n",
    "#                offline=False,\n",
    "#                latency=100,\n",
    "#                downloadThroughput=93750,\n",
    "#                uploadThroughput=31250,\n",
    "#                connectionType='cellular3g')\n",
    "\n",
    "# tab.call_method('Console.enable', _timeout=20)\n",
    "# # output_on_start with no brackets : not running the function but passing the function object\n",
    "# tab.set_listener('Network.requestWillBeSent', output_on_start)\n",
    "# tab.set_listener('Network.responseRecieved', output_on_end)\n",
    "tab.call_method('Console.enable', _timeout=20)\n",
    "tab.set_listener('Console.ConsoleMessage')\n",
    "\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://chromedevtools.github.io/devtools-protocol/tot/Console/#type-ConsoleMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = driver.find_elements_by_css_selector('#country-code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"2f31e460826bd7c19ffdcaa9e56055ee\", element=\"3af25591-d405-4de9-8cce-8a7e24d8c220\")>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 140, 'y': 8} {'height': 40, 'width': 0}\n"
     ]
    }
   ],
   "source": [
    "location = element[0].location\n",
    "size = element[0].size\n",
    "print(location, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-f2e3238a9c36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlocation2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msize2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "location2 = element[1].location\n",
    "size2 = element[1].size\n",
    "print(location, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "png = driver.get_screenshot_as_png()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(BytesIO(png))\n",
    "\n",
    "left = location['x']\n",
    "top = location['y']\n",
    "right = location['x'] + size['width']\n",
    "bottom = location['y'] + size['height']\n",
    "\n",
    "im = im.crop((left, top, right, bottom))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(BytesIO(png))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "fox = webdriver.Firefox()\n",
    "fox.get('http://stackoverflow.com/')\n",
    "\n",
    "# now that we have the preliminary stuff out of the way time to get that image :D\n",
    "element = fox.find_element_by_id('hlogo') # find part of the page you want image of\n",
    "location = element.location\n",
    "size = element.size\n",
    "png = fox.get_screenshot_as_png() # saves screenshot of entire page\n",
    "fox.quit()\n",
    "\n",
    "im = Image.open(BytesIO(png)) # uses PIL library to open image in memory\n",
    "\n",
    "left = location['x']\n",
    "top = location['y']\n",
    "right = location['x'] + size['width']\n",
    "bottom = location['y'] + size['height']\n",
    "\n",
    "\n",
    "im = im.crop((left, top, right, bottom)) # defines crop points\n",
    "im.save('screenshot.png') # saves new cropped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"3aece7358f3515058daa696b53b33af1\", element=\"c50fff67-b5ab-45c5-a4a8-79ac38c78cfc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"3aece7358f3515058daa696b53b33af1\", element=\"926d95a5-d680-448e-9127-6f215cd72019\")>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when urls.txt is downloaded move txt file to Download-Google-Images repository\n",
    "# add new folder called images unless it already exists\n",
    "# for multiple classes you have to make sub folders for each different classes in the images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python download_images.py --urls urls.txt --output #images/hotdog example in the tutorial video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "ChromeOptions options = new ChromeOptions();\n",
    "options.AddArgument(\"--start-maximized\");\n",
    "options.AddArguments(\"disable-infobars\");\n",
    "options.AddArguments(\"--disable-notifications\");\n",
    "options.AddArguments(\"--auto-open-devtools-for-tabs\");\n",
    "driver = new ChromeDriver(DrivePath, options, TimeSpan.FromSeconds(100));\n",
    "\n",
    "#browser exposes an executable file\n",
    "#Through Selenium test we will invoke the executable file which will then\n",
    "#invoke actual browser\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=\"C:\\\\chromedriver.exe\")\n",
    "# to maximize the browser window\n",
    "driver.maximize_window()\n",
    "#get method to launch the URL\n",
    "driver.get(\"https://www.tutorialspoint.com/about/about_careers.htm\")\n",
    "#to refresh the browser\n",
    "driver.refresh()\n",
    "# identifying the source element\n",
    "source= driver.find_element_by_xpath(\"//*[text()='Company']\");\n",
    "# action chain object creation\n",
    "action = ActionChains(driver)\n",
    "# right click operation and then perform\n",
    "action.context_click(source).perform()\n",
    "#to close the browser\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://stackoverflow.com/questions/37683576/how-do-you-automatically-open-the-chrome-devtools-tab-within-selenium-c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
